1.爬虫（实现了对糗事百科的抓取）
1.1
urlib2.urlopen（）可以用来爬一个网页的html文件
1.2
有些网站可能需要我们设置header（https://cuiqingcai.com/954.html）
1.3
URLError
可能出现的原因有：网络无连接，连接不到制定的服务器，服务器不存在
可以用try except语句进行包围并捕获相应的异常
HTTPError是URLError的子类，在你利用urlopen方法发出一个请求时，
服务器上都会对应一个应答对象response，其中它包含一个数字”状态码”。
举个例子，假如response是一个”重定向”，需定位到别的地址获取文档，
urllib2将对此进行处理。
1.4
1.4.1
cookie使用
cookie使用来辨别用户身份，进行session跟踪而储存在用于本地终端上的数据
比如在某些需要登录的页面，我们可以把库保存在我们的登录cookie里，然后就
可以进行抓取了。
1.4.2
cookie是在客户端记录信息确定用户身份，session是在服务器端记录信息确定用户身份
1.5
Beautiful Soup
Beautiful Soup是python的一个库，最主要的功能是从网页抓取数据


2.numpy
numpy有许多进行矩阵运算的好用的函数
Series形式是一个一维索引dict
DataFrame类似于一个二维的索引表格
