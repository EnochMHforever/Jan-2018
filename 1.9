1.tensorflow

2.机器学习
2.1 GAN
N是指神经网络，GAN实际上也是一种神经网络
G是指生成模型：机器学习的模型可以分成两类，一类是判别模型，一类是生成模型
判别模型比较简单，输出目标较为简单，损失函数比较容定义。而生成模型是用来直接生成
一个对象，比较抽象
A是指对抗
G的目标是使得自己生成的噪声能够以假乱真，而D的目的是把G生成的噪声检查出来
这样两者就能形成对抗
2.2
SVM
模型会对一个类别进行评分，评分代表可能性的大小

max（0，-）是一种合叶损失，还有平方合叶损失，更加强烈地惩罚过界的边界值，
正则化法相是对某些特带你的权值添加一些偏好，而对其他的权重不添加美因茨就达到消除模糊性的目的
，常见的是L2范式正则化罚项

Softmax
参数方法的又是在于一旦学习到了参数，就可以把训练数据进行抛弃了，而且可以通过矩阵乘法运算来实现

softmax和svm都是分类器，softmax使用的是合页损失，而svm使用的是交叉熵损失
针对一个数据点，SVM和Softmax分类器的不同处理方式的例子。两个分类器都计算
了同样的分值向量f（本节中是通过矩阵乘来实现）。不同之处在于对f中分值的解释：
SVM分类器将它们看做是分类评分，它的损失函数鼓励正确的分类（本例中是蓝色的类别2）
的分值比其他分类的分值高出至少一个边界值。Softmax分类器将这些数值看做是每个分类
没有归一化的对数概率，鼓励正确分类的归一化的对数概率变高，其余的变低。SVM的最终的
损失值是1.58，Softmax的最终的损失值是0.452，但要注意这两个数值没有可比性。只在给
定同样数据，在同样的分类器的损失值计算中，它们才有意义。

2.3
最优化方法
1.随机搜索最大的（不可行）
核心思路（迭代优化）
找到最优的权重是十分困难的，甚至是不可能的，所以我们的方法是，嘴一个权重集去油，使得它的损失逐渐减少

2.随机本地搜索
第一个策略是没走一步就尝试几种随机方向，如果某个方向是向山下的，就再该方向上走一步

3.跟随梯度
前两个策略都是尝试再权重空间找一个方向，能够降低损失值，其实不用寻找方向，二十可以计算出最好的方向，也就是梯度方向
